# app/emergency_diagnostic.py
import pandas as pd
import numpy as np
from pathlib import Path
import joblib
import json
from sklearn.metrics import classification_report, confusion_matrix


def emergency_diagnostic():
    """–°—Ä–æ—á–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø—Ä–æ–±–ª–µ–º —Å AI –º–æ–¥–µ–ª—è–º–∏"""
    print("=== EMERGENCY AI DIAGNOSTIC ===")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–æ–¥–µ–ª–∏
    models_dir = Path("models")
    out_dir = Path("out")

    # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π
    model_files = {
        "strategy": "ai_strategy.pkl",
        "strategy_optimized": "ai_strategy_optimized.pkl",
        "risk": "ai_risk.pkl",
        "risk_optimized": "ai_risk_optimized.pkl"
    }

    print("1. MODEL FILES CHECK:")
    for name, file in model_files.items():
        path = models_dir / file
        exists = path.exists()
        print(f"   {name}: {'‚úÖ' if exists else '‚ùå'} {file}")
        if exists:
            try:
                model = joblib.load(path)
                print(f"      Type: {type(model)}")
                if hasattr(model, 'steps'):
                    print(f"      Steps: {[type(s[1]).__name__ for s in model.steps]}")
            except Exception as e:
                print(f"      Error loading: {e}")

    # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–µ—Ç—Ä–∏–∫ –æ–±—É—á–µ–Ω–∏—è
    metrics_path = out_dir / "train_metrics.json"
    if metrics_path.exists():
        with open(metrics_path, 'r') as f:
            metrics = json.load(f)
        print(f"\n2. TRAINING METRICS:")
        for k, v in metrics.items():
            print(f"   {k}: {v:.4f}")
    else:
        print("\n2. TRAINING METRICS: ‚ùå No metrics file")

    # 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
    try:
        from app.train_ai import build_dataset
        X, y_sig, y_reg = build_dataset()
        print(f"\n3. DATASET ANALYSIS:")
        print(f"   Features shape: {X.shape}")
        print(f"   Signal labels: {pd.Series(y_sig).value_counts().to_dict()}")
        print(f"   Regime labels: {pd.Series(y_reg).value_counts().to_dict()}")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ñ–∏—á
        print(f"   Feature stats:")
        for col in X.columns[:5]:  # –ü–µ—Ä–≤—ã–µ 5 —Ñ–∏—á
            print(f"     {col}: mean={X[col].mean():.4f}, std={X[col].std():.4f}")

    except Exception as e:
        print(f"\n3. DATASET ANALYSIS: ‚ùå Error - {e}")

    # 4. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
    print(f"\n4. PREDICTION TEST:")
    try:
        from app.ai_models import AIStrategyModel
        model = AIStrategyModel()
        if model.available():
            # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
            test_features = pd.DataFrame({
                'price_efficiency': [0.1, -0.1, 0.5, -0.5],
                'volume_anomaly': [1.0, -1.0, 2.0, -2.0],
                'trend_strength': [0.5, -0.5, 1.0, -1.0],
                'momentum_5': [0.01, -0.01, 0.02, -0.02]
            })

            predictions = model.predict_series(test_features)
            print(f"   Test predictions: {predictions.tolist()}")
            print(f"   Unique predictions: {predictions.unique()}")
        else:
            print("   ‚ùå Model not available")
    except Exception as e:
        print(f"   ‚ùå Prediction test failed: {e}")

    # 5. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    print(f"\n5. EMERGENCY RECOMMENDATIONS:")
    recommendations = [
        "üö® –ü–ï–†–ï–û–ë–£–ß–ò–¢–¨ –ú–û–î–ï–õ–ò —Å –¥—Ä—É–≥–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏",
        "üö® –£–í–ï–õ–ò–ß–ò–¢–¨ –û–ë–™–ï–ú –î–ê–ù–ù–´–• –¥–ª—è –æ–±—É—á–µ–Ω–∏—è",
        "üö® –ü–†–û–í–ï–†–ò–¢–¨ –ö–ê–ß–ï–°–¢–í–û –ú–ï–¢–û–ö –≤ features.py",
        "üö® –ò–°–ü–û–õ–¨–ó–û–í–ê–¢–¨ –ü–†–û–°–¢–´–ï –°–¢–†–ê–¢–ï–ì–ò–ò –∫–∞–∫ fallback",
        "üö® –ü–†–û–í–ï–†–ò–¢–¨ –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –§–ò–ß –Ω–∞ –Ω–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç—å"
    ]

    for rec in recommendations:
        print(f"   {rec}")


if __name__ == "__main__":
    emergency_diagnostic()