# app/emergency_retrain_fixed.py
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import cross_val_score, TimeSeriesSplit
import joblib
from pathlib import Path


def emergency_retrain_fixed():
    """–≠–∫—Å—Ç—Ä–µ–Ω–Ω–æ–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ —Å–æ —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω—ã–º–∏ —Ñ–∏—á–∞–º–∏ –∏ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏"""
    print("=== EMERGENCY RETRAIN WITH FIXED DATA ===")

    # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–∞—à–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
    from app.stationary_features import calculate_stationary_features
    from app.fixed_labels import make_better_labels
    from app.utils import load_all
    from app.config import config

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    data = load_all("data", config.symbols_cfg.symbols)

    frames = []
    for s, df in data.items():
        # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ —Ñ–∏—á–∏
        feats = calculate_stationary_features(df)
        feats["symbol"] = s
        feats["close"] = df["close"]
        frames.append(feats)

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥–∞—Ç–∞—Å–µ—Ç
    ds = pd.concat(frames).sort_index()

    # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
    y = make_better_labels(ds["close"])

    # –§–∏—á–∏ (–∏—Å–∫–ª—é—á–∞–µ–º –Ω–µ—á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏)
    feature_cols = [col for col in ds.columns if col not in ['symbol', 'close']]
    X = ds[feature_cols].copy()

    # –£–±–∏—Ä–∞–µ–º NaN
    mask = (~X.isna().any(axis=1)) & (~y.isna())
    X = X[mask]
    y = y[mask]

    print(f"Fixed dataset: {X.shape}, labels: {y.value_counts().to_dict()}")

    # –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –∫–ª–∞—Å—Å–æ–≤
    from sklearn.utils import class_weight
    classes = np.unique(y)
    weights = class_weight.compute_class_weight('balanced', classes=classes, y=y)
    class_weights = dict(zip(classes, weights))
    print(f"Class weights: {class_weights}")

    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ä–∞–∑–Ω—ã–µ –º–æ–¥–µ–ª–∏
    models = {
        'rf_balanced': RandomForestClassifier(
            n_estimators=200, max_depth=20,
            class_weight=class_weights, random_state=42, n_jobs=-1
        ),
        'gbm_balanced': GradientBoostingClassifier(
            n_estimators=150, max_depth=10, random_state=42
        ),
        'logreg_balanced': LogisticRegression(
            class_weight=class_weights, random_state=42, max_iter=1000
        )
    }

    # –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è
    tscv = TimeSeriesSplit(n_splits=3)
    results = {}

    for name, model in models.items():
        pipeline = Pipeline([
            ('scaler', StandardScaler()),
            ('model', model)
        ])

        # –î–ª—è –º–Ω–æ–≥–æ–∫–ª–∞—Å—Å–æ–≤–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º accuracy
        scores = cross_val_score(pipeline, X, y, cv=tscv, scoring='accuracy')
        results[name] = {
            'mean_accuracy': scores.mean(),
            'std_accuracy': scores.std(),
            'model': pipeline
        }
        print(f"{name}: Accuracy = {scores.mean():.4f} ¬± {scores.std():.4f}")

    # –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å
    best_name = max(results.keys(), key=lambda x: results[x]['mean_accuracy'])
    best_model = results[best_name]['model']
    best_score = results[best_name]['mean_accuracy']

    print(f"\nüéØ BEST MODEL: {best_name} with Accuracy = {best_score:.4f}")

    # –î–æ–æ–±—É—á–∞–µ–º –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö
    best_model.fit(X, y)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    models_dir = Path("models")
    models_dir.mkdir(exist_ok=True)
    joblib.dump(best_model, models_dir / "ai_strategy_fixed.pkl")

    # –ê–Ω–∞–ª–∏–∑ –≤–∞–∂–Ω–æ—Å—Ç–∏ —Ñ–∏—á
    if hasattr(best_model.named_steps['model'], 'feature_importances_'):
        importances = best_model.named_steps['model'].feature_importances_
        feat_importance = pd.DataFrame({
            'feature': feature_cols,
            'importance': importances
        }).sort_values('importance', ascending=False)

        print(f"\nTOP 10 FEATURES:")
        print(feat_importance.head(10))

    return best_model


if __name__ == "__main__":
    emergency_retrain_fixed()